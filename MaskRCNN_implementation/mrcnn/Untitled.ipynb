{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Sequence(Sequence):\n",
    "\n",
    "    def __init__(self, dataset, config, shuffle=True, augment=False, augmentation=None,\n",
    "                   random_rois=0, batch_size=1, detection_targets=False,\n",
    "                   no_augmentation_sources=None):\n",
    "    self.b = 0  # batch item index\n",
    "    self.image_index = -1\n",
    "    self.image_ids = np.copy(dataset.image_ids)\n",
    "    self.error_count = 0\n",
    "    self.no_augmentation_sources = no_augmentation_sources or []\n",
    "    self.dataset = dataset\n",
    "    self.config = config\n",
    "    self.shuffle = shuffle\n",
    "    self.augment = augment\n",
    "    self.augmentation = augmentation\n",
    "    self.random_rois = random_rois\n",
    "    self.batch_size = batch_size\n",
    "    self.detection_targets = detection_targets\n",
    "    self.no_augmentation_sources = no_augmentation_sources\n",
    "    # Anchors\n",
    "    # [anchor_count, (y1, x1, y2, x2)]\n",
    "    self.backbone_shapes = compute_backbone_shapes(config, config.IMAGE_SHAPE)\n",
    "    self.anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES,\n",
    "                                             config.RPN_ANCHOR_RATIOS,\n",
    "                                             backbone_shapes,\n",
    "                                             config.BACKBONE_STRIDES,\n",
    "                                             config.RPN_ANCHOR_STRIDE)\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.image_ids) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        b = 0\n",
    "        self.image_index = idx*self.batch_size\n",
    "        while:\n",
    "#             self.image_index = (self.image_index + 1) % len(self.image_ids)\n",
    "#             if self.shuffle and self.image_index == 0:\n",
    "#                 np.random.shuffle(self.image_ids)\n",
    "\n",
    "            # Get GT bounding boxes and masks for image.\n",
    "            image_id = self.image_ids[self.image_index]\n",
    "\n",
    "            # If the image source is not to be augmented pass None as augmentation\n",
    "            if self.dataset.image_info[image_id]['source'] in self.no_augmentation_sources:\n",
    "                image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                load_image_gt(self.dataset, self.config, image_id, augment=self.augment,\n",
    "                              augmentation=None,\n",
    "                              use_mini_mask=self.config.USE_MINI_MASK)\n",
    "            else:\n",
    "                image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                    load_image_gt(self.dataset, self.config, image_id, augment=self.augment,\n",
    "                                augmentation=self.augmentation,\n",
    "                                use_mini_mask=self.config.USE_MINI_MASK)\n",
    "\n",
    "            # Skip images that have no instances. This can happen in cases\n",
    "            # where we train on a subset of classes and the image doesn't\n",
    "            # have any of the classes we care about.\n",
    "            if not np.any(gt_class_ids > 0):\n",
    "                continue\n",
    "\n",
    "            # RPN Targets\n",
    "            rpn_match, rpn_bbox = build_rpn_targets(image.shape, anchors,\n",
    "                                                    gt_class_ids, gt_boxes, self.config)\n",
    "\n",
    "            # Mask R-CNN Targets\n",
    "            if random_rois:\n",
    "                rpn_rois = generate_random_rois(\n",
    "                    image.shape, random_rois, gt_class_ids, gt_boxes)\n",
    "                if detection_targets:\n",
    "                    rois, mrcnn_class_ids, mrcnn_bbox, mrcnn_mask =\\\n",
    "                        build_detection_targets(\n",
    "                            rpn_rois, gt_class_ids, gt_boxes, gt_masks, config)\n",
    "\n",
    "            # Init batch arrays\n",
    "            if b == 0:\n",
    "                batch_image_meta = np.zeros(\n",
    "                    (batch_size,) + image_meta.shape, dtype=image_meta.dtype)\n",
    "                batch_rpn_match = np.zeros(\n",
    "                    [batch_size, anchors.shape[0], 1], dtype=rpn_match.dtype)\n",
    "                batch_rpn_bbox = np.zeros(\n",
    "                    [batch_size, config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4], dtype=rpn_bbox.dtype)\n",
    "                batch_images = np.zeros(\n",
    "                    (batch_size,) + image.shape, dtype=np.float32)\n",
    "                batch_gt_class_ids = np.zeros(\n",
    "                    (batch_size, config.MAX_GT_INSTANCES), dtype=np.int32)\n",
    "                batch_gt_boxes = np.zeros(\n",
    "                    (batch_size, config.MAX_GT_INSTANCES, 4), dtype=np.int32)\n",
    "                batch_gt_masks = np.zeros(\n",
    "                    (batch_size, gt_masks.shape[0], gt_masks.shape[1],\n",
    "                     config.MAX_GT_INSTANCES), dtype=gt_masks.dtype)\n",
    "                if random_rois:\n",
    "                    batch_rpn_rois = np.zeros(\n",
    "                        (batch_size, rpn_rois.shape[0], 4), dtype=rpn_rois.dtype)\n",
    "                    if detection_targets:\n",
    "                        batch_rois = np.zeros(\n",
    "                            (batch_size,) + rois.shape, dtype=rois.dtype)\n",
    "                        batch_mrcnn_class_ids = np.zeros(\n",
    "                            (batch_size,) + mrcnn_class_ids.shape, dtype=mrcnn_class_ids.dtype)\n",
    "                        batch_mrcnn_bbox = np.zeros(\n",
    "                            (batch_size,) + mrcnn_bbox.shape, dtype=mrcnn_bbox.dtype)\n",
    "                        batch_mrcnn_mask = np.zeros(\n",
    "                            (batch_size,) + mrcnn_mask.shape, dtype=mrcnn_mask.dtype)\n",
    "\n",
    "            # If more instances than fits in the array, sub-sample from them.\n",
    "            if gt_boxes.shape[0] > self.config.MAX_GT_INSTANCES:\n",
    "                ids = np.random.choice(\n",
    "                    np.arange(gt_boxes.shape[0]), self.config.MAX_GT_INSTANCES, replace=False)\n",
    "                gt_class_ids = gt_class_ids[ids]\n",
    "                gt_boxes = gt_boxes[ids]\n",
    "                gt_masks = gt_masks[:, :, ids]\n",
    "\n",
    "            # Add to batch\n",
    "            batch_image_meta[b] = image_meta\n",
    "            batch_rpn_match[b] = rpn_match[:, np.newaxis]\n",
    "            batch_rpn_bbox[b] = rpn_bbox\n",
    "            batch_images[b] = mold_image(image.astype(np.float32), self.config)\n",
    "            batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids\n",
    "            batch_gt_boxes[b, :gt_boxes.shape[0]] = gt_boxes\n",
    "            batch_gt_masks[b, :, :, :gt_masks.shape[-1]] = gt_masks\n",
    "            if random_rois:\n",
    "                batch_rpn_rois[b] = rpn_rois\n",
    "                if detection_targets:\n",
    "                    batch_rois[b] = rois\n",
    "                    batch_mrcnn_class_ids[b] = mrcnn_class_ids\n",
    "                    batch_mrcnn_bbox[b] = mrcnn_bbox\n",
    "                    batch_mrcnn_mask[b] = mrcnn_mask\n",
    "            b += 1\n",
    "            self.image_index += 1\n",
    "            # Batch full?\n",
    "            if b >= self.batch_size:\n",
    "                inputs = [batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox,\n",
    "                          batch_gt_class_ids, batch_gt_boxes, batch_gt_masks]\n",
    "                outputs = []\n",
    "\n",
    "                if random_rois:\n",
    "                    inputs.extend([batch_rpn_rois])\n",
    "                    if detection_targets:\n",
    "                        inputs.extend([batch_rois])\n",
    "                        # Keras requires that output and targets have the same number of dimensions\n",
    "                        batch_mrcnn_class_ids = np.expand_dims(\n",
    "                            batch_mrcnn_class_ids, -1)\n",
    "                        outputs.extend(\n",
    "                            [batch_mrcnn_class_ids, batch_mrcnn_bbox, batch_mrcnn_mask])\n",
    "\n",
    "#                 yield inputs, outputs\n",
    "\n",
    "                # start a new batch\n",
    "                b = 0\n",
    "                break            \n",
    "\n",
    "        return inputs, outputs\n",
    "\n",
    "def data_generator(dataset, config, shuffle=True, augment=False, augmentation=None,\n",
    "                   random_rois=0, batch_size=1, detection_targets=False,\n",
    "                   no_augmentation_sources=None):\n",
    "    \"\"\"A generator that returns images and corresponding target class ids,\n",
    "    bounding box deltas, and masks.\n",
    "\n",
    "    dataset: The Dataset object to pick data from\n",
    "    config: The model config object\n",
    "    shuffle: If True, shuffles the samples before every epoch\n",
    "    augment: (deprecated. Use augmentation instead). If true, apply random\n",
    "        image augmentation. Currently, only horizontal flipping is offered.\n",
    "    augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.\n",
    "        For example, passing imgaug.augmenters.Fliplr(0.5) flips images\n",
    "        right/left 50% of the time.\n",
    "    random_rois: If > 0 then generate proposals to be used to train the\n",
    "                 network classifier and mask heads. Useful if training\n",
    "                 the Mask RCNN part without the RPN.\n",
    "    batch_size: How many images to return in each call\n",
    "    detection_targets: If True, generate detection targets (class IDs, bbox\n",
    "        deltas, and masks). Typically for debugging or visualizations because\n",
    "        in trainig detection targets are generated by DetectionTargetLayer.\n",
    "    no_augmentation_sources: Optional. List of sources to exclude for\n",
    "        augmentation. A source is string that identifies a dataset and is\n",
    "        defined in the Dataset class.\n",
    "\n",
    "    Returns a Python generator. Upon calling next() on it, the\n",
    "    generator returns two lists, inputs and outputs. The contents\n",
    "    of the lists differs depending on the received arguments:\n",
    "    inputs list:\n",
    "    - images: [batch, H, W, C]\n",
    "    - image_meta: [batch, (meta data)] Image details. See compose_image_meta()\n",
    "    - rpn_match: [batch, N] Integer (1=positive anchor, -1=negative, 0=neutral)\n",
    "    - rpn_bbox: [batch, N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas.\n",
    "    - gt_class_ids: [batch, MAX_GT_INSTANCES] Integer class IDs\n",
    "    - gt_boxes: [batch, MAX_GT_INSTANCES, (y1, x1, y2, x2)]\n",
    "    - gt_masks: [batch, height, width, MAX_GT_INSTANCES]. The height and width\n",
    "                are those of the image unless use_mini_mask is True, in which\n",
    "                case they are defined in MINI_MASK_SHAPE.\n",
    "\n",
    "    outputs list: Usually empty in regular training. But if detection_targets\n",
    "        is True then the outputs list contains target class_ids, bbox deltas,\n",
    "        and masks.\n",
    "    \"\"\"\n",
    "    b = 0  # batch item index\n",
    "    image_index = -1\n",
    "    image_ids = np.copy(dataset.image_ids)\n",
    "    error_count = 0\n",
    "    no_augmentation_sources = no_augmentation_sources or []\n",
    "\n",
    "    # Anchors\n",
    "    # [anchor_count, (y1, x1, y2, x2)]\n",
    "    backbone_shapes = compute_backbone_shapes(config, config.IMAGE_SHAPE)\n",
    "    anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES,\n",
    "                                             config.RPN_ANCHOR_RATIOS,\n",
    "                                             backbone_shapes,\n",
    "                                             config.BACKBONE_STRIDES,\n",
    "                                             config.RPN_ANCHOR_STRIDE)\n",
    "\n",
    "    # Keras requires a generator to run indefinitely.\n",
    "    while True:\n",
    "        try:\n",
    "            # Increment index to pick next image. Shuffle if at the start of an epoch.\n",
    "            image_index = (image_index + 1) % len(image_ids)\n",
    "            if shuffle and image_index == 0:\n",
    "                np.random.shuffle(image_ids)\n",
    "\n",
    "            # Get GT bounding boxes and masks for image.\n",
    "            image_id = image_ids[image_index]\n",
    "\n",
    "            # If the image source is not to be augmented pass None as augmentation\n",
    "            if dataset.image_info[image_id]['source'] in no_augmentation_sources:\n",
    "                image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                load_image_gt(dataset, config, image_id, augment=augment,\n",
    "                              augmentation=None,\n",
    "                              use_mini_mask=config.USE_MINI_MASK)\n",
    "            else:\n",
    "                image, image_meta, gt_class_ids, gt_boxes, gt_masks = \\\n",
    "                    load_image_gt(dataset, config, image_id, augment=augment,\n",
    "                                augmentation=augmentation,\n",
    "                                use_mini_mask=config.USE_MINI_MASK)\n",
    "\n",
    "            # Skip images that have no instances. This can happen in cases\n",
    "            # where we train on a subset of classes and the image doesn't\n",
    "            # have any of the classes we care about.\n",
    "            if not np.any(gt_class_ids > 0):\n",
    "                continue\n",
    "\n",
    "            # RPN Targets\n",
    "            rpn_match, rpn_bbox = build_rpn_targets(image.shape, anchors,\n",
    "                                                    gt_class_ids, gt_boxes, config)\n",
    "\n",
    "            # Mask R-CNN Targets\n",
    "            if random_rois:\n",
    "                rpn_rois = generate_random_rois(\n",
    "                    image.shape, random_rois, gt_class_ids, gt_boxes)\n",
    "                if detection_targets:\n",
    "                    rois, mrcnn_class_ids, mrcnn_bbox, mrcnn_mask =\\\n",
    "                        build_detection_targets(\n",
    "                            rpn_rois, gt_class_ids, gt_boxes, gt_masks, config)\n",
    "\n",
    "            # Init batch arrays\n",
    "            if b == 0:\n",
    "                batch_image_meta = np.zeros(\n",
    "                    (batch_size,) + image_meta.shape, dtype=image_meta.dtype)\n",
    "                batch_rpn_match = np.zeros(\n",
    "                    [batch_size, anchors.shape[0], 1], dtype=rpn_match.dtype)\n",
    "                batch_rpn_bbox = np.zeros(\n",
    "                    [batch_size, config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4], dtype=rpn_bbox.dtype)\n",
    "                batch_images = np.zeros(\n",
    "                    (batch_size,) + image.shape, dtype=np.float32)\n",
    "                batch_gt_class_ids = np.zeros(\n",
    "                    (batch_size, config.MAX_GT_INSTANCES), dtype=np.int32)\n",
    "                batch_gt_boxes = np.zeros(\n",
    "                    (batch_size, config.MAX_GT_INSTANCES, 4), dtype=np.int32)\n",
    "                batch_gt_masks = np.zeros(\n",
    "                    (batch_size, gt_masks.shape[0], gt_masks.shape[1],\n",
    "                     config.MAX_GT_INSTANCES), dtype=gt_masks.dtype)\n",
    "                if random_rois:\n",
    "                    batch_rpn_rois = np.zeros(\n",
    "                        (batch_size, rpn_rois.shape[0], 4), dtype=rpn_rois.dtype)\n",
    "                    if detection_targets:\n",
    "                        batch_rois = np.zeros(\n",
    "                            (batch_size,) + rois.shape, dtype=rois.dtype)\n",
    "                        batch_mrcnn_class_ids = np.zeros(\n",
    "                            (batch_size,) + mrcnn_class_ids.shape, dtype=mrcnn_class_ids.dtype)\n",
    "                        batch_mrcnn_bbox = np.zeros(\n",
    "                            (batch_size,) + mrcnn_bbox.shape, dtype=mrcnn_bbox.dtype)\n",
    "                        batch_mrcnn_mask = np.zeros(\n",
    "                            (batch_size,) + mrcnn_mask.shape, dtype=mrcnn_mask.dtype)\n",
    "\n",
    "            # If more instances than fits in the array, sub-sample from them.\n",
    "            if gt_boxes.shape[0] > config.MAX_GT_INSTANCES:\n",
    "                ids = np.random.choice(\n",
    "                    np.arange(gt_boxes.shape[0]), config.MAX_GT_INSTANCES, replace=False)\n",
    "                gt_class_ids = gt_class_ids[ids]\n",
    "                gt_boxes = gt_boxes[ids]\n",
    "                gt_masks = gt_masks[:, :, ids]\n",
    "\n",
    "            # Add to batch\n",
    "            batch_image_meta[b] = image_meta\n",
    "            batch_rpn_match[b] = rpn_match[:, np.newaxis]\n",
    "            batch_rpn_bbox[b] = rpn_bbox\n",
    "            batch_images[b] = mold_image(image.astype(np.float32), config)\n",
    "            batch_gt_class_ids[b, :gt_class_ids.shape[0]] = gt_class_ids\n",
    "            batch_gt_boxes[b, :gt_boxes.shape[0]] = gt_boxes\n",
    "            batch_gt_masks[b, :, :, :gt_masks.shape[-1]] = gt_masks\n",
    "            if random_rois:\n",
    "                batch_rpn_rois[b] = rpn_rois\n",
    "                if detection_targets:\n",
    "                    batch_rois[b] = rois\n",
    "                    batch_mrcnn_class_ids[b] = mrcnn_class_ids\n",
    "                    batch_mrcnn_bbox[b] = mrcnn_bbox\n",
    "                    batch_mrcnn_mask[b] = mrcnn_mask\n",
    "            b += 1\n",
    "\n",
    "            # Batch full?\n",
    "            if b >= batch_size:\n",
    "                inputs = [batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox,\n",
    "                          batch_gt_class_ids, batch_gt_boxes, batch_gt_masks]\n",
    "                outputs = []\n",
    "\n",
    "                if random_rois:\n",
    "                    inputs.extend([batch_rpn_rois])\n",
    "                    if detection_targets:\n",
    "                        inputs.extend([batch_rois])\n",
    "                        # Keras requires that output and targets have the same number of dimensions\n",
    "                        batch_mrcnn_class_ids = np.expand_dims(\n",
    "                            batch_mrcnn_class_ids, -1)\n",
    "                        outputs.extend(\n",
    "                            [batch_mrcnn_class_ids, batch_mrcnn_bbox, batch_mrcnn_mask])\n",
    "\n",
    "                yield inputs, outputs\n",
    "\n",
    "                # start a new batch\n",
    "                b = 0\n",
    "        except (GeneratorExit, KeyboardInterrupt):\n",
    "            raise\n",
    "        except:\n",
    "            # Log it and skip the image\n",
    "            logging.exception(\"Error processing image {}\".format(\n",
    "                dataset.image_info[image_id]))\n",
    "            error_count += 1\n",
    "            if error_count > 5:\n",
    "                raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
